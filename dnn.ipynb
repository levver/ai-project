{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mehxqr9zXXJy",
    "colab_type": "text"
   },
   "source": [
    "Things that didnt work : \n",
    "\n",
    "  simple LSTM model\n",
    "\n",
    "  simple MLP model\n",
    "\n",
    "  Adding normalization\n",
    "\n",
    "  balancing data\n",
    "\n",
    "\n",
    "\n",
    "Sources\n",
    "\n",
    "Architecture choices - https://arxiv.org/pdf/1809.04356.pdf , \n",
    "https://arxiv.org/pdf/1611.06455.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% Imports\n"
    },
    "id": "lbIM6enCLTJh",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121.0
    },
    "outputId": "ca56acf7-9534-4cc4-9be5-a6e04341c2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import functools\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# CONSTANTS\n",
    "TARGET_PROFIT = 1.1\n",
    "SEED = 1337\n",
    "VAL_FRACTION = 0.2\n",
    "models = [\"mlp\",\"fcn\",\"resnet\"]\n",
    "feature_maps = [32,64,128]\n",
    "batch_sizes = [16,32,64]\n",
    "lrs = [1e-3,1e-4,1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PxY7MwiJEiNC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def normalize_df(df):\n",
    "  df[\"ma_gap\"] = df.apply(lambda row: [row.ma50[i] - row.ma200[i] for i in range(len(row.ma50))][1:], axis=1)\n",
    "  df[\"deriv\"] = df[\"ma200\"].apply(lambda x: list(pd.DataFrame(x).diff().iloc[1:,0]))\n",
    "  df[\"RSI\"] = df[\"RSI\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
    "  df[\"close\"] = df[\"close\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
    "  df[\"ma50\"] = df[\"ma50\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
    "  df[\"ma200\"] = df[\"ma200\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
    "  df[\"ema200\"] = df[\"ema200\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
    "  df[\"volume\"] = df[\"volume\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%% Model\n"
    },
    "id": "KuitAeSFLTJy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def prep_data(df,val=False):\n",
    "\n",
    "  x_dim = len(df[\"close\"][0])\n",
    "  y_dim = len(df.columns) - 1\n",
    "\n",
    "  if val:\n",
    "    val_df = df.sample(frac=VAL_FRACTION, random_state=SEED)\n",
    "    train_df = df.drop(val_df.index)\n",
    "    x_val = np.array([val_df[col] for col in val_df.drop(\"target\",axis=1)], dtype=np.float64).reshape((-1,x_dim,y_dim))\n",
    "    y_val = np.array(val_df.target, dtype=np.bool)\n",
    "  else:\n",
    "    train_df = df\n",
    "    x_val = None\n",
    "    y_val = None\n",
    "\n",
    "\n",
    "  x_train = np.array([train_df[col] for col in train_df.drop(\"target\",axis=1)], dtype=np.float64).reshape((-1,x_dim,y_dim))\n",
    "  y_train = np.array(train_df.target, dtype=np.bool)\n",
    "\n",
    "  return x_dim, y_dim, x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "octg6S9cIBb7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def build_model(model_type,input_shape,feature_maps,lr):\n",
    "  if model_type==\"resnet\":\n",
    "    return build_resnet(input_shape,feature_maps,lr)\n",
    "  elif model_type==\"fcn\":\n",
    "    return build_fcn(input_shape,feature_maps,lr)\n",
    "  else:\n",
    "    return build_mlp(input_shape,feature_maps,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "axlzyVo9LTKD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def build_resnet(input_shape,feature_maps,lr):\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        # BLOCK 1\n",
    "\n",
    "        conv_x = keras.layers.Conv1D(filters=feature_maps, kernel_size=8, padding='same')(input_layer)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        shortcut_y = keras.layers.Conv1D(filters=feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "\n",
    "        # BLOCK 2\n",
    "\n",
    "        conv_x = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        shortcut_y = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "\n",
    "        # BLOCK 3\n",
    "\n",
    "        conv_x = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "        output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "\n",
    "        # FINAL\n",
    "\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "        output_layer = keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vjNOirkUv8qI",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def build_fcn(input_shape,feature_maps,lr):\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        conv1 = keras.layers.Conv1D(filters=feature_maps, kernel_size=8, padding='same')(input_layer)\n",
    "        conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "        conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "\n",
    "        conv2 = keras.layers.Conv1D(filters=feature_maps*2, kernel_size=5, padding='same')(conv1)\n",
    "        conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "        conv2 = keras.layers.Activation('relu')(conv2)\n",
    "\n",
    "        conv3 = keras.layers.Conv1D(feature_maps, kernel_size=3,padding='same')(conv2)\n",
    "        conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "        conv3 = keras.layers.Activation('relu')(conv3)\n",
    "\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "        output_layer = keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q3bipgQ2Hs8N",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, feature_maps, lr):\n",
    "  input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "  input_layer_flattened = keras.layers.Flatten()(input_layer)\n",
    "  \n",
    "  layer_1 = keras.layers.Dropout(0.1)(input_layer_flattened)\n",
    "  layer_1 = keras.layers.Dense(feature_maps, activation='relu')(layer_1)\n",
    "\n",
    "  layer_2 = keras.layers.Dropout(0.2)(layer_1)\n",
    "  layer_2 = keras.layers.Dense(feature_maps, activation='relu')(layer_2)\n",
    "\n",
    "  layer_3 = keras.layers.Dropout(0.2)(layer_2)\n",
    "  layer_3 = keras.layers.Dense(feature_maps, activation='relu')(layer_3)\n",
    "\n",
    "  output_layer = keras.layers.Dropout(0.3)(layer_3)\n",
    "  output_layer = keras.layers.Dense(1, activation='sigmoid')(output_layer)\n",
    "  model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nUJ6cTSrJEhp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('Training Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.ylim(-0.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vkYuFhVSNgsT",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def test_accuracy(model,x_test,y_test):\n",
    "    y_pred = model.predict(x_test) > 0.5\n",
    "    if np.unique(y_pred) == 1:\n",
    "      return 0\n",
    "    y_test = y_test.reshape(2030,1)\n",
    "    return np.count_nonzero(np.logical_and(y_test,y_pred))/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mY1N5D8fVOFp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(accuracies):\n",
    "  plt.title('Configuration Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  x = range(len(accuracies))\n",
    "  plt.bar(x, accuracies.values())\n",
    "  plt.xticks(x, accuracies.keys())\n",
    "  plt.ylim(-0.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tZdjgdleWvC5",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def plot_best(accuracies, models):\n",
    "  plt.title('Model Best Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  x = range(len(models))\n",
    "  values = [max([accuracies[key] for key in accuracies if model in key]) for model in models]\n",
    "  plt.bar(x, values)\n",
    "  plt.xticks(x, models)\n",
    "  plt.ylim(-0.1, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "biUJUj0nRLOf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "Path(\"./figs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_url = \"/content/drive/My Drive/Colab Notebooks/data_set.pkl\"\n",
    "df = pd.read_pickle(data_url).drop(\"ticker\", axis=1)\n",
    "test_url = \"/content/drive/My Drive/Colab Notebooks/test_set.pkl\"\n",
    "test_df = pd.read_pickle(test_url).drop(\"ticker\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wDlx38TkS3Qc",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471.0
    },
    "outputId": "8b487814-3e4e-4f0c-d954-e47440832943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp_FM32_LR0.001_BS16\n",
      "Accuracy : 0\n",
      "Training mlp_FM32_LR0.001_BS32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3f883ff03045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training {name}_FM{maps}_LR{lr}_BS{batch_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name}_FM{maps}_LR{lr}_BS{batch_size}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mplot_training_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df = normalize_df(df)\n",
    "test_df = normalize_df(test_df)\n",
    "x_dim, y_dim, x_train, y_train, x_val, y_val = prep_data(df,val=True)\n",
    "x_test_dim, y_test_dim, x_test, y_test, _, _ = prep_data(test_df)\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "for name in models:\n",
    "  for maps in feature_maps:\n",
    "    for lr in lrs:\n",
    "      model = build_model(name,(x_dim,y_dim),maps,lr)\n",
    "      model.save_weights('temp.hdf5',)\n",
    "      for batch_size in batch_sizes:\n",
    "        model.load_weights('temp.hdf5')\n",
    "        print(f\"Training {name}_FM{maps}_LR{lr}_BS{batch_size}\")\n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=100, verbose=0, validation_data=(x_val, y_val))\n",
    "        model.save(f'{name}_FM{maps}_LR{lr}_BS{batch_size}.hdf5')\n",
    "        plot_training_history(history)\n",
    "        plt.savefig(f'figs/training_{name}_FM{maps}_LR{lr}_BS{batch_size}.png')\n",
    "        plt.close()\n",
    "        accuracy = test_accuracy(model, x_test, y_test)\n",
    "        print(f\"Accuracy : {accuracy}\")\n",
    "        accuracies[f'{name}_FM{maps}_LR{lr}_BS{batch_size}'] = accuracy \n",
    "print(\"Finished training\")\n",
    "plot_accuracy(accuracies)\n",
    "plt.savefig(f'figs/accuracies.png')\n",
    "plt.close()\n",
    "plot_best(accuracies, models)\n",
    "plt.savefig(f'figs/best_models.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "colab": {
   "name": "dnn.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
