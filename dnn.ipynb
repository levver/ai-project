{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "dnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mehxqr9zXXJy",
        "colab_type": "text"
      },
      "source": [
        "Things that didnt work : \n",
        "\n",
        "  simple LSTM model\n",
        "\n",
        "  simple MLP model\n",
        "\n",
        "  Adding normalization\n",
        "\n",
        "  balancing data\n",
        "\n",
        "\n",
        "\n",
        "Sources\n",
        "\n",
        "Architecture choices - https://arxiv.org/pdf/1809.04356.pdf , \n",
        "https://arxiv.org/pdf/1611.06455.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Imports\n"
        },
        "id": "lbIM6enCLTJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "05eda092-b999-4487-a96e-930bc339e81f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import functools\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# CONSTANTS\n",
        "TARGET_PROFIT = 1.1\n",
        "SEED = 1337\n",
        "VAL_FRACTION = 0.2\n",
        "models = [\"mlp\",\"fcn\",\"resnet\"]\n",
        "feature_maps = [32,64,128]\n",
        "batch_sizes = [16,32,64]\n",
        "lrs = [1e-3,1e-4,1e-5]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e62b1a58e984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# CONSTANTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxY7MwiJEiNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_df(df):\n",
        "  df[\"ma_gap\"] = df.apply(lambda row: [row.ma50[i] - row.ma200[i] for i in range(len(row.ma50))][1:], axis=1)\n",
        "  df[\"deriv\"] = df[\"ma200\"].apply(lambda x: list(pd.DataFrame(x).diff().iloc[1:,0]))\n",
        "  df[\"RSI\"] = df[\"RSI\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
        "  df[\"close\"] = df[\"close\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
        "  df[\"ma50\"] = df[\"ma50\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
        "  df[\"ma200\"] = df[\"ma200\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
        "  df[\"ema200\"] = df[\"ema200\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
        "  df[\"volume\"] = df[\"volume\"].apply(lambda x: np.asarray(x[1:])/np.max(x)*2-1)\n",
        "  return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Model\n"
        },
        "id": "KuitAeSFLTJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_data(df,val=False):\n",
        "\n",
        "  x_dim = len(df[\"close\"][0])\n",
        "  y_dim = len(df.columns) - 1\n",
        "\n",
        "  if val:\n",
        "    val_df = df.sample(frac=VAL_FRACTION, random_state=SEED)\n",
        "    train_df = df.drop(val_df.index)\n",
        "    x_val = np.array([val_df[col] for col in val_df.drop(\"target\",axis=1)], dtype=np.float64).reshape((-1,x_dim,y_dim))\n",
        "    y_val = np.array(val_df.target, dtype=np.bool)\n",
        "  else:\n",
        "    train_df = df\n",
        "    x_val = None\n",
        "    y_val = None\n",
        "\n",
        "\n",
        "  x_train = np.array([train_df[col] for col in train_df.drop(\"target\",axis=1)], dtype=np.float64).reshape((-1,x_dim,y_dim))\n",
        "  y_train = np.array(train_df.target, dtype=np.bool)\n",
        "\n",
        "  return x_dim, y_dim, x_train, y_train, x_val, y_val"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "octg6S9cIBb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(model_type,input_shape,feature_maps,lr):\n",
        "  if model_type==\"resnet\":\n",
        "    return build_resnet(input_shape,feature_maps,lr)\n",
        "  elif model_type==\"fcn\":\n",
        "    return build_fcn(input_shape,feature_maps,lr)\n",
        "  else:\n",
        "    return build_mlp(input_shape,feature_maps,lr)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "axlzyVo9LTKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_resnet(input_shape,feature_maps,lr):\n",
        "        input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "        # BLOCK 1\n",
        "\n",
        "        conv_x = keras.layers.Conv1D(filters=feature_maps, kernel_size=8, padding='same')(input_layer)\n",
        "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "\n",
        "        conv_y = keras.layers.Conv1D(filters=feature_maps, kernel_size=5, padding='same')(conv_x)\n",
        "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "\n",
        "        conv_z = keras.layers.Conv1D(filters=feature_maps, kernel_size=3, padding='same')(conv_y)\n",
        "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "        shortcut_y = keras.layers.Conv1D(filters=feature_maps, kernel_size=1, padding='same')(input_layer)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
        "        output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
        "\n",
        "        # BLOCK 2\n",
        "\n",
        "        conv_x = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
        "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "\n",
        "        conv_y = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "\n",
        "        conv_z = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "        shortcut_y = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
        "        output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
        "\n",
        "        # BLOCK 3\n",
        "\n",
        "        conv_x = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
        "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "\n",
        "        conv_y = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "\n",
        "        conv_z = keras.layers.Conv1D(filters=feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "        shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
        "\n",
        "        output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
        "        output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
        "\n",
        "        # FINAL\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
        "\n",
        "        output_layer = keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n",
        "\n",
        "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjNOirkUv8qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_fcn(input_shape,feature_maps,lr):\n",
        "        input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "        conv1 = keras.layers.Conv1D(filters=feature_maps, kernel_size=8, padding='same')(input_layer)\n",
        "        conv1 = keras.layers.BatchNormalization()(conv1)\n",
        "        conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
        "\n",
        "        conv2 = keras.layers.Conv1D(filters=feature_maps*2, kernel_size=5, padding='same')(conv1)\n",
        "        conv2 = keras.layers.BatchNormalization()(conv2)\n",
        "        conv2 = keras.layers.Activation('relu')(conv2)\n",
        "\n",
        "        conv3 = keras.layers.Conv1D(feature_maps, kernel_size=3,padding='same')(conv2)\n",
        "        conv3 = keras.layers.BatchNormalization()(conv3)\n",
        "        conv3 = keras.layers.Activation('relu')(conv3)\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
        "\n",
        "        output_layer = keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n",
        "\n",
        "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3bipgQ2Hs8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_mlp(input_shape, feature_maps, lr):\n",
        "  input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "  input_layer_flattened = keras.layers.Flatten()(input_layer)\n",
        "  \n",
        "  layer_1 = keras.layers.Dropout(0.1)(input_layer_flattened)\n",
        "  layer_1 = keras.layers.Dense(feature_maps, activation='relu')(layer_1)\n",
        "\n",
        "  layer_2 = keras.layers.Dropout(0.2)(layer_1)\n",
        "  layer_2 = keras.layers.Dense(feature_maps, activation='relu')(layer_2)\n",
        "\n",
        "  layer_3 = keras.layers.Dropout(0.2)(layer_2)\n",
        "  layer_3 = keras.layers.Dense(feature_maps, activation='relu')(layer_3)\n",
        "\n",
        "  output_layer = keras.layers.Dropout(0.3)(layer_3)\n",
        "  output_layer = keras.layers.Dense(1, activation='sigmoid')(output_layer)\n",
        "  model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUJ6cTSrJEhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_training_history(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Training Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.ylim(-0.1, 1.1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkYuFhVSNgsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,x_test,y_test):\n",
        "    y_pred = model.predict(x_test) > 0.5\n",
        "    if np.unique(y_pred) == 1:\n",
        "      return 0\n",
        "    y_test = y_test.reshape(2030,1)\n",
        "    return np.count_nonzero(np.logical_and(y_test,y_pred))/len(y_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY1N5D8fVOFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy(accuracies):\n",
        "  plt.title('Configuration Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  x = range(len(accuracies))\n",
        "  plt.bar(x, accuracies.values())\n",
        "  plt.xticks(x, accuracies.keys())\n",
        "  plt.ylim(-0.1, 1.1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdjgdleWvC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_best(accuracies, models):\n",
        "  plt.title('Model Best Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  x = range(len(models))\n",
        "  values = [max([accuracies[key] for key in accuracies if model in key]) for model in models]\n",
        "  plt.bar(x, values)\n",
        "  plt.xticks(x, models)\n",
        "  plt.ylim(-0.1, 1.1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDlx38TkS3Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(df):\n",
        "  Path(\"./figs\").mkdir(parents=True, exist_ok=True)\n",
        "  df = pd.read_pickle(\"data_set.pkl\").drop(\"ticker\", axis=1)\n",
        "  df = normalize_df(df)\n",
        "\n",
        "  x_dim, y_dim, x_train, y_train, x_val, y_val = prep_data(df,val=True)\n",
        "\n",
        "  for name in models:\n",
        "    for maps in feature_maps:\n",
        "      for lr in lrs:\n",
        "        model = build_model(name,(x_dim,y_dim),maps,lr)\n",
        "        model.save_weights('temp.hdf5',)\n",
        "        for batch_size in batch_sizes:\n",
        "          model.load_weights('temp.hdf5')\n",
        "          print(f\"Training {name}_FM{maps}_LR{lr}_BS{batch_size}\")\n",
        "          history = model.fit(x_train, y_train, batch_size=batch_size, epochs=100, verbose=0, validation_data=(x_val, y_val))\n",
        "          model.save(f'{name}_FM{maps}_LR{lr}_BS{batch_size}.hdf5')\n",
        "          plot_training_history(history)\n",
        "          plt.savefig(f'figs/training_{name}_FM{maps}_LR{lr}_BS{batch_size}.png')\n",
        "          plt.close()\n",
        "  print(\"Finished training\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MF85INFAXG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model):\n",
        "  test_df = pd.read_pickle(\"test_set.pkl\").drop(\"ticker\", axis=1)\n",
        "  test_df = normalize_df(test_df)\n",
        "  x_test_dim, y_test_dim, x_test, y_test, _, _ = prep_data(test_df)\n",
        "  accuracy = predict(model,x_test,y_test)\n",
        "  print(f\"Test accuracy : {accuracy}\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjbwZeRYOXdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  df = pd.read_pickle(\"data_set.pkl\").drop(\"ticker\", axis=1)\n",
        "  df = normalize_df(df)\n",
        "\n",
        "  x_dim, y_dim, x_train, y_train, x_val, y_val = prep_data(df,val=True)\n",
        "  model = build_model(\"resnet\",(x_dim,y_dim),64,0.001)\n",
        "  model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=0, validation_data=(x_val, y_val))\n",
        "  test(model)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiqe-ofuQStw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f50eba1f-7366-40b0-e750-a2bcfcc59dc5"
      },
      "source": [
        "main()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-a54cae700558>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_set.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ticker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mx_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_set.pkl'"
          ]
        }
      ]
    }
  ]
}